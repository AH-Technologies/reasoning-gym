# Base Configuration for GRPO Training
# This file contains all default settings that can be overridden

# Model Configuration
model:
  name: "Qwen/Qwen2.5-7B-Instruct"
  torch_dtype: "bfloat16"
  low_cpu_mem_usage: true

# Dataset Configuration
data:
  task_name: "leg_counting"
  num_examples: 1024
  seed: 42

# Training Configuration
training:
  output_dir: "./output"
  num_train_epochs: 1
  per_device_train_batch_size: 8
  gradient_accumulation_steps: 4
  learning_rate: 1.0e-6
  lr_scheduler_type: "constant_with_warmup"
  warmup_steps: 10
  num_generations: 8  # Must divide evenly into (batch_size * grad_accumulation)
  temperature: 0.7
  max_grad_norm: 0.2
  logging_steps: 1
  save_steps: 50
  bf16: true
  gradient_checkpointing: true  # Save memory by recomputing activations

# Reward Configuration
rewards:
  - name: "correctness"
    weight: 1.0

# Logging Configuration
logging:
  report_to: "wandb"  # Can be "wandb", "tensorboard", or "none"
  project_name: null  # Will use default if null
  run_name: null  # Will auto-generate if null

# Environment Configuration
environment:
  seed: 42
  set_seed_everywhere: true
